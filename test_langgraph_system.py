"""
Script de test pour le nouveau syst√®me LangGraph Multi-Agents V2.

Usage:
    python test_langgraph_system.py
"""
import asyncio
import sys
from datetime import datetime

# Test imports
try:
    from src.ai_agents.workflow import generate_profile_questions, analyze_and_create_profile
    from src.ai_agents.agent_state import create_initial_state
    from src.ai_agents.shared_context import shared_context_service
    print("‚úÖ Imports r√©ussis")
except Exception as e:
    print(f"‚ùå Erreur d'import : {e}")
    sys.exit(1)


async def test_workflow():
    """Test complet du workflow LangGraph"""

    print("\n" + "="*60)
    print("üß™ TEST DU SYST√àME LANGGRAPH MULTI-AGENTS V2")
    print("="*60 + "\n")

    # === Test 1 : G√©n√©ration de questions ===
    print("üìù Test 1 : G√©n√©ration de questions")
    print("-" * 40)

    test_user_profile = {
        "id": "test-user-123",
        "nom": "Test",
        "prenom": "User",
        "username": "testuser",
        "email": "test@example.com",
        "status": "Etudiant",
        "niveau_technique": 5,
        "competences": ["Python", "Machine Learning"],
        "objectifs_apprentissage": "Ma√Ætriser le Deep Learning",
        "motivation": "Changer de carri√®re",
        "niveau_energie": 7
    }

    try:
        result = await generate_profile_questions(
            user_id="test-user-123",
            user_profile=test_user_profile
        )

        print(f"‚úÖ Questions g√©n√©r√©es avec succ√®s")
        print(f"   - Session ID: {result['session_id']}")
        print(f"   - Nombre de questions: {len(result.get('questions', []))}")
        print(f"   - Niveau estim√©: {result.get('user_level')}/10")

        # Analyser les types de questions
        questions = result.get('questions', [])
        types_count = {}
        for q in questions:
            qtype = q.get('type', 'Unknown')
            types_count[qtype] = types_count.get(qtype, 0) + 1

        print(f"   - Types de questions:")
        for qtype, count in types_count.items():
            emoji = "‚ö†Ô∏è" if qtype in ["QuestionOuverte", "ListeOuverte"] else "üìã"
            print(f"     {emoji} {qtype}: {count}")

        open_questions = types_count.get("QuestionOuverte", 0) + types_count.get("ListeOuverte", 0)
        open_percentage = (open_questions / len(questions) * 100) if questions else 0

        if open_percentage >= 30:
            print(f"   ‚úÖ Taux de questions ouvertes: {open_percentage:.1f}% (>= 30%)")
        else:
            print(f"   ‚ö†Ô∏è Taux de questions ouvertes: {open_percentage:.1f}% (< 30%)")

        session_id = result['session_id']

    except Exception as e:
        print(f"‚ùå Erreur lors de la g√©n√©ration: {e}")
        import traceback
        traceback.print_exc()
        return

    # === Test 2 : Cr√©ation de r√©ponses factices ===
    print("\nüìù Test 2 : Cr√©ation de r√©ponses factices")
    print("-" * 40)

    test_responses = []
    for q in questions:
        response = {
            "numero": q.get("numero"),
            "type": q.get("type")
        }

        if q.get("type") == "ChoixMultiple":
            response["reponse"] = "A"
        elif q.get("type") == "VraiOuFaux":
            response["reponse"] = "A"
        elif q.get("type") == "QuestionOuverte":
            response["reponse"] = "La backpropagation est un algorithme qui propage l'erreur en arri√®re √† travers les couches du r√©seau de neurones, en utilisant la r√®gle de d√©rivation en cha√Æne pour calculer les gradients."
        elif q.get("type") == "ListeOuverte":
            response["reponse"] = "CNN, RNN, LSTM"

        test_responses.append(response)

    print(f"‚úÖ {len(test_responses)} r√©ponses factices cr√©√©es")

    # === Test 3 : Analyse des r√©ponses ===
    print("\nüìù Test 3 : Analyse des r√©ponses (Multi-Agents)")
    print("-" * 40)
    print("   ü§ñ EvaluatorAgent ‚Üí √âvalue les r√©ponses")
    print("   üéì TutoringAgent ‚Üí Cr√©e le parcours RPG")

    try:
        result = await analyze_and_create_profile(
            user_id="test-user-123",
            session_id=session_id,
            responses=test_responses
        )

        print(f"\n‚úÖ Analyse termin√©e avec succ√®s")
        print(f"\nüìä R√âSULTATS DE L'√âVALUATION:")
        print(f"   - Niveau final: {result.get('user_level')}/10")

        eval_results = result.get('evaluation_results', {})
        eval_globale = eval_results.get('evaluation_globale', {})

        print(f"   - Score QCM/VF: {eval_globale.get('score_qcm_vf', 0):.1f}/10")
        print(f"   - Moyenne questions ouvertes: {eval_globale.get('moyenne_questions_ouvertes', 0):.1f}/10")

        forces = result.get('strengths', [])
        faiblesses = result.get('weaknesses', [])

        print(f"\nüí™ FORCES IDENTIFI√âES ({len(forces)}):")
        for force in forces[:3]:
            print(f"   ‚úì {force}")

        print(f"\n‚ö†Ô∏è FAIBLESSES IDENTIFI√âES ({len(faiblesses)}):")
        for faiblesse in faiblesses[:3]:
            print(f"   ‚úó {faiblesse}")

        # Parcours d'apprentissage
        learning_path = result.get('learning_path', {})
        quetes = learning_path.get('quetes_principales', [])
        boss_fights = learning_path.get('boss_fights', [])

        print(f"\nüéÆ PARCOURS D'APPRENTISSAGE RPG:")
        print(f"   - Qu√™tes principales: {len(quetes)}")
        print(f"   - Boss Fights: {len(boss_fights)}")

        if quetes:
            print(f"\n   Premi√®re qu√™te:")
            print(f"   {quetes[0].get('titre', 'Sans titre')}")
            print(f"   XP: {quetes[0].get('xp', 0)} | Badge: {quetes[0].get('badge', 'Aucun')}")

        badges = result.get('badges_earned', [])
        print(f"\nüèÜ BADGES D√âBLOQU√âS ({len(badges)}):")
        for badge in badges:
            print(f"   üéñÔ∏è {badge}")

        recommendations = result.get('recommendations', [])
        print(f"\nüí° RECOMMANDATIONS ({len(recommendations)}):")
        for rec in recommendations[:3]:
            print(f"   ‚Üí {rec}")

    except Exception as e:
        print(f"‚ùå Erreur lors de l'analyse: {e}")
        import traceback
        traceback.print_exc()
        return

    # === Test 4 : Contexte partag√© ===
    print("\nüìù Test 4 : V√©rification du contexte partag√©")
    print("-" * 40)

    try:
        context = await shared_context_service.get_context(
            user_id="test-user-123",
            session_id=session_id
        )

        if context:
            print(f"‚úÖ Contexte r√©cup√©r√© depuis PostgreSQL/Redis")
            print(f"   - √âtat actuel: {context.get('current_state')}")
            print(f"   - Interactions totales: {context.get('total_interactions')}")
            print(f"   - Messages dans l'historique: {len(context.get('conversation_history', []))}")

            # Afficher les 3 derniers messages
            conv_history = context.get('conversation_history', [])
            if conv_history:
                print(f"\n   Derniers messages:")
                for msg in conv_history[-3:]:
                    print(f"   [{msg.get('agent')}] {msg.get('message')[:60]}...")
        else:
            print(f"‚ö†Ô∏è Aucun contexte trouv√©")

    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration du contexte: {e}")
        import traceback
        traceback.print_exc()

    # === R√©sum√© final ===
    print("\n" + "="*60)
    print("‚úÖ TESTS TERMIN√âS")
    print("="*60)
    print(f"\nüéØ Le syst√®me LangGraph Multi-Agents V2 est op√©rationnel !")
    print(f"\nüìö Documentation:")
    print(f"   - Architecture: ARCHITECTURE_MULTI_AGENTS.md")
    print(f"   - Migration: MIGRATION_LANGGRAPH.md")
    print(f"\nüöÄ Endpoints disponibles:")
    print(f"   - POST /api/profile/v2/generate-questions")
    print(f"   - POST /api/profile/v2/submit-responses")
    print(f"   - GET  /api/profile/v2/learning-path")
    print(f"   - GET  /api/profile/v2/workflow-state/{{session_id}}")


if __name__ == "__main__":
    print("üöÄ D√©marrage des tests...")

    # V√©rifier que les d√©pendances sont install√©es
    try:
        import langgraph
        import langchain_openai
        print("‚úÖ D√©pendances LangGraph install√©es")
    except ImportError as e:
        print(f"‚ùå D√©pendances manquantes: {e}")
        print("   Ex√©cutez: pip install langgraph langchain langchain-openai")
        sys.exit(1)

    # V√©rifier la config
    try:
        from src.config import Config
        if not Config.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY not set")
        print("‚úÖ Configuration OpenAI OK")
    except Exception as e:
        print(f"‚ùå Erreur de configuration: {e}")
        sys.exit(1)

    # Lancer les tests
    asyncio.run(test_workflow())

