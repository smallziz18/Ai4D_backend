import asyncio
from celery import Celery
import logging
from asgiref.sync import async_to_sync

from src.mail import create_message, mail
from src.config import Config
from types import SimpleNamespace
import json
import re

# Configuration Celery
app = Celery(
    'tasks',
    broker=getattr(Config, 'REDIS_URL', None) or f"redis://{Config.REDIS_HOST}:{Config.REDIS_PORT}/{Config.REDIS_DB}",
    backend=getattr(Config, 'REDIS_URL', None) or f"redis://{Config.REDIS_HOST}:{Config.REDIS_PORT}/{Config.REDIS_DB}"
)

# Configuration suppl√©mentaire
app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
    task_soft_time_limit=120,  # 120 secondes soft limit (augment√© pour LLM + roadmap)
    task_time_limit=180,  # 180 secondes hard limit
    worker_prefetch_multiplier=1,
    worker_max_tasks_per_child=1000,
)

# Logger
logger = logging.getLogger(__name__)

# Loop utilitaire partag√© par le worker Celery
_worker_loop = None

def _get_worker_loop():
    """Retourne une boucle event persistante pour √©viter les fermetures intempestives."""
    global _worker_loop
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            return loop
    except RuntimeError:
        pass
    if _worker_loop is None or _worker_loop.is_closed():
        _worker_loop = asyncio.new_event_loop()
    asyncio.set_event_loop(_worker_loop)
    return _worker_loop


def _get_level_label(niveau: int) -> str:
    """Convertir niveau num√©rique (1-10) en label descriptif"""
    labels = {
        1: "Novice",
        2: "D√©butant",
        3: "Apprenti",
        4: "Initi√©",
        5: "Interm√©diaire",
        6: "Confirm√©",
        7: "Avanc√©",
        8: "Expert",
        9: "Ma√Ætre",
        10: "Grand Ma√Ætre"
    }
    return labels.get(niveau, "D√©butant")


@app.task(bind=True, max_retries=3)
def send_email(self, recipients, subject, body):
    """
    T√¢che d'envoi d'email asynchrone avec retry.
    Utilise une approche enti√®rement asynchrone pour √©viter les blocages.
    """
    try:
        import asyncio

        message = create_message(recipients, subject, body)

        # Cr√©er et ex√©cuter une coroutine
        async def send_async():
            return await mail.send_message(message)

        # Essayer d'obtenir la boucle d'√©v√©nement courante
        try:
            loop = asyncio.get_running_loop()
            # Si on est d√©j√† dans une boucle, cela signifie qu'on est dans un contexte async
            # Ce ne devrait pas arriver dans une t√¢che Celery, mais on g√®re le cas
            logger.warning("Running loop detected, using asyncio.run may fail")
        except RuntimeError:
            # Pas de boucle d'√©v√©nement actuelle, c'est normal
            loop = None

        # Ex√©cuter avec asyncio.run qui cr√©e une nouvelle boucle
        try:
            asyncio.run(send_async())
        except Exception as e:
            logger.error(f"asyncio.run failed: {e}, trying async_to_sync")
            from asgiref.sync import async_to_sync
            async_to_sync(send_async)()

        logger.info(f"‚úÖ Email envoy√© avec succ√®s √†: {recipients}")
        return {"status": "success", "message": f"Email envoy√© √† {recipients}"}

    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'envoi d'email: {str(e)}")
        # Retry avec backoff exponentiel (2s, 4s, 8s)
        countdown = min(2 ** self.request.retries, 8)
        try:
            raise self.retry(exc=e, countdown=countdown)
        except self.MaxRetriesExceededError:
            logger.critical(f"‚ùå Impossible d'envoyer l'email apr√®s {self.max_retries} tentatives: {recipients}")
            return {"status": "failed", "error": str(e), "max_retries_exceeded": True}


def _fallback_question(user: dict) -> str:
    """Fallback d√©terministe si LLM indisponible."""
    status = str(user.get('status', '') or '')
    if status == 'Etudiant':
        parts = []
        competences = user.get('competences') or []
        if competences:
            parts.append(f"Tu connais d√©j√† {', '.join(competences)}.")
        objectifs = user.get('objectifs_apprentissage')
        if objectifs:
            parts.append(f"Ton objectif est: {objectifs}.")
        base = "Quelle est la prochaine comp√©tence que tu aimerais d√©velopper dans les 2 semaines √† venir ?"
        return (" ".join(parts) + " " + base).strip()
    if status == 'Professeur':
        parts = []
        specialites = user.get('specialites') or []
        if specialites:
            parts.append(f"Tes sp√©cialit√©s: {', '.join(specialites)}.")
        motiv = user.get('motivation_principale')
        if motiv:
            parts.append(f"Ta motivation principale: {motiv}.")
        base = "Quel est le principal d√©fi p√©dagogique que tu souhaites adresser avec tes apprenants ?"
        return (" ".join(parts) + " " + base).strip()
    return "Quel est ton principal objectif d'apprentissage cette semaine ?"



def _clean_json_like(text: str):
    """Nettoie une sortie type Markdown ```json ... ``` et tente de parser en JSON."""
    if not isinstance(text, str):
        return None, None

    # 1. Enlever les fences ```json ... ``` ou ```...```
    cleaned = re.sub(r"^```(?:json)?\s*\n?|\n?```\s*$", "", text.strip())

    # 2. Enlever les espaces en d√©but de lignes (indentation)
    lines = cleaned.split('\n')
    cleaned = '\n'.join(line.strip() for line in lines)

    # 3. Tenter de charger directement en JSON
    try:
        parsed = json.loads(cleaned)
        return cleaned, parsed
    except Exception:
        pass

    # 4. Tenter de trouver un objet JSON ou array dans le texte
    try:
        start_brace = cleaned.find('{')
        start_bracket = cleaned.find('[')

        if start_brace != -1 and (start_bracket == -1 or start_brace < start_bracket):
            depth = 0
            for i in range(start_brace, len(cleaned)):
                if cleaned[i] == '{':
                    depth += 1
                elif cleaned[i] == '}':
                    depth -= 1
                    if depth == 0:
                        json_str = cleaned[start_brace:i+1]
                        parsed = json.loads(json_str)
                        return json_str, parsed
        elif start_bracket != -1:
            depth = 0
            for i in range(start_bracket, len(cleaned)):
                if cleaned[i] == '[':
                    depth += 1
                elif cleaned[i] == ']':
                    depth -= 1
                    if depth == 0:
                        json_str = cleaned[start_bracket:i+1]
                        parsed = json.loads(json_str)
                        return json_str, parsed
    except Exception:
        pass

    return cleaned, None


@app.task(name="chatbot_task", bind=True)
def chatbot_task(self, user_id: str, session_id: str, message: str, user_context: dict = None):
    """T√¢che async pour le chatbot IA - avec event loop propre"""
    import asyncio

    try:
        # Import √† l'int√©rieur de la t√¢che pour √©viter les effets de bord de fork
        from src.ai_agents.agents.chatbot_agent import ChatbotAgent
        from src.profile.learning_services import chatbot_service

        # Cr√©er une instance locale (√©vite partage d'objets non fork-safe)
        local_agent = ChatbotAgent()

        # Cr√©er un nouvel event loop pour ce worker (√©vite "Event loop is closed")
        try:
            loop = asyncio.get_event_loop()
            if loop.is_closed():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        # Ex√©cuter le chatbot avec le nouvel event loop
        response = loop.run_until_complete(local_agent.chat(
            user_id=user_id,
            session_id=session_id,
            message=message,
            user_context=user_context
        ))

        # Sauvegarder dans MongoDB
        loop.run_until_complete(chatbot_service.add_message(
            utilisateur_id=user_id,
            session_id=session_id,
            role="user",
            content=message
        ))

        loop.run_until_complete(chatbot_service.add_message(
            utilisateur_id=user_id,
            session_id=session_id,
            role="assistant",
            content=response.get("response", "")
        ))

        return {
            "status": "success",
            "response": response,
            "task_id": self.request.id
        }
    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        print(f"Erreur chatbot_task: {str(e)}")
        print(f"Traceback complet:\n{error_trace}")
        return {
            "status": "failed",
            "error": str(e),
            "traceback": error_trace,
            "task_id": self.request.id
        }


@app.task(name="module_completion_task", bind=True)
def module_completion_task(self, user_id: str, course_id: str, module_id: str, score: float, time_spent: int):
    """T√¢che async pour la compl√©tion de module"""
    try:
        from src.ai_agents.agents.course_manager_agent import course_manager_agent
        from src.profile.learning_services import progression_service
        from src.profile.services import profile_service

        # Valider la compl√©tion
        validation_result = async_to_sync(course_manager_agent.validate_module_completion)(
            user_id=user_id,
            session_id=f"course_{course_id}",
            module_id=module_id,
            evaluation_results={
                "score": score,
                "seuil_reussite": 70
            }
        )

        if validation_result.get("module_completed"):
            # Marquer comme compl√©t√©
            async_to_sync(progression_service.complete_module)(
                utilisateur_id=user_id,
                course_id=course_id,
                module_id=module_id,
                evaluation_result={
                    "score": score,
                    "passed": True,
                    "date": json.dumps(json.loads(json.dumps(str(__import__('datetime').datetime.now())))[:-1], default=str)
                }
            )

            # Ajouter du temps
            async_to_sync(progression_service.add_time_spent)(
                utilisateur_id=user_id,
                course_id=course_id,
                minutes=time_spent,
                module_id=module_id
            )

            # Gagner XP
            profil = async_to_sync(profile_service.get_profile_by_user_id)(user_id)
            if profil:
                async_to_sync(profile_service.add_xp)(
                    user_id,
                    validation_result.get("xp_gained", 200)
                )

        return {
            "status": "success",
            "validation_result": validation_result,
            "task_id": self.request.id
        }
    except Exception as e:
        print(f"Erreur module_completion_task: {str(e)}")
        return {
            "status": "failed",
            "error": str(e),
            "task_id": self.request.id
        }


@app.task(name="generate_profile_question_task")
def generate_profile_question_task(user_data: dict):
    """G√©n√®re une question personnalis√©e (LLM si dispo), sinon fallback.
    Retourne un objet avec question brute et JSON pars√© si applicable.
    """
    try:
        try:
            from src.ai_agents.profiler.question_generator import generate_profile_question as llm_generate
        except Exception:
            llm_generate = None

        if llm_generate:
            try:
                # Utiliser un objet simple avec attributs pour satisfaire la signature attendue
                user_obj = SimpleNamespace(**user_data)
                question = llm_generate(user_obj)
                cleaned, parsed = _clean_json_like(question)
                if parsed and isinstance(parsed, list) and len(parsed) > 0:
                    return {"ok": True, "source": "llm", "question": cleaned or question, "json": parsed}
                else:
                    # Si le parsing √©choue, utiliser le fallback
                    print(f"LLM parsing failed, using fallback. Raw: {question[:200] if question else 'None'}")
            except Exception as e:
                print(f"LLM generation failed: {e}, using fallback")
                # fallback si LLM √©choue
                pass

        # Fallback: g√©n√©rer des questions de base
        q = _fallback_question(user_data)
        return {"ok": True, "source": "fallback", "question": q, "json": None}
    except Exception as e:
        return {"ok": False, "error": str(e)}


@app.task(name="profile_analysis_task")
def profile_analysis_task(user_data: dict, evaluation: dict, is_initial: bool = False, domaine: str = "G√©n√©ral"):
    """
    Analyse les r√©sultats du quiz avec gamification compl√®te et met √† jour le profil.
    Utilise async_to_sync pour √©viter les probl√®mes d'event loop.
    """
    try:
        from src.ai_agents.profiler.profile_analyzer import analyze_profile_with_llm
        from src.profile.services import profile_service
        from uuid import UUID as _UUID

        print(f"[PROFILE_ANALYSIS] Starting analysis for user: {user_data.get('username', 'unknown')}")
        print(f"[PROFILE_ANALYSIS] Is initial questionnaire: {is_initial}")

        # 1) Extraire user_id
        user_id_raw = user_data.get('id')
        try:
            user_uuid = _UUID(str(user_id_raw))
        except Exception:
            user_uuid = str(user_id_raw)

        # 2) Analyser avec le LLM
        llm_analysis = None
        try:
            user_json = json.dumps(user_data, default=str, ensure_ascii=False)
            evaluation_json = json.dumps(evaluation, ensure_ascii=False)

            print(f"[PROFILE_ANALYSIS] Calling LLM for deep analysis with domain context: {domaine}...")
            llm_text = analyze_profile_with_llm(user_json, evaluation_json, domaine)

            cleaned, parsed = _clean_json_like(llm_text)
            if isinstance(parsed, dict):
                llm_analysis = parsed
                print(f"[PROFILE_ANALYSIS] LLM analysis completed successfully")
        except Exception as llm_error:
            print(f"[PROFILE_ANALYSIS] LLM analysis failed: {llm_error}, continuing without it")

        # 3) Traiter selon le type de questionnaire
        if is_initial:
            print(f"[PROFILE_ANALYSIS] Processing initial questionnaire...")

            # ‚úÖ UTILISER async_to_sync pour toutes les op√©rations async
            async def _initial_questionnaire():
                """Fonction pour g√©rer le questionnaire initial (op√©rations async)"""
                # Cr√©er ou r√©cup√©rer le profil
                profile = await profile_service.get_profile_by_user_id(user_uuid)

                if not profile:
                    print(f"[PROFILE_ANALYSIS] Creating MongoDB profile for user {user_uuid}")
                    from src.profile.schema import ProfilCreate

                    # D√©terminer le niveau initial
                    initial_level = 1
                    if llm_analysis and isinstance(llm_analysis, dict):
                        lvl = int(llm_analysis.get("niveau", 0) or 0)
                        if 1 <= lvl <= 10:
                            initial_level = lvl
                            print(f"[PROFILE_ANALYSIS] Level from LLM: {initial_level}")

                    # Cr√©er le profil
                    profile_data = ProfilCreate(
                        utilisateur_id=user_uuid,
                        domaine=domaine,
                        niveau=initial_level,
                        xp=0,
                        badges=[],
                        competences=[],
                        energie=5
                    )

                    try:
                        profile = await profile_service.create_profile(profile_data)
                        print(f"[PROFILE_ANALYSIS] MongoDB profile created: {profile.id}")
                    except Exception as e:
                        print(f"[PROFILE_ANALYSIS] Error creating profile: {e}")
                        profile = await profile_service.get_profile_by_user_id(user_uuid)
                        if not profile:
                            raise

                # Sauvegarder le questionnaire
                updated_profile = await profile_service.save_initial_questionnaire(
                    user_uuid,
                    evaluation,
                    analyse_llm=llm_analysis
                )

                # Mettre √† jour le niveau si le LLM l'a fourni
                if llm_analysis and isinstance(llm_analysis, dict):
                    update_fields = {}
                    lvl = llm_analysis.get("niveau")
                    if isinstance(lvl, (int, float)):
                        lvl = int(lvl)
                        if 1 <= lvl <= 10:
                            update_fields["niveau"] = lvl

                    if update_fields:
                        await profile_service.collection.update_one(
                            {"utilisateur_id": str(user_uuid)},
                            {"$set": update_fields}
                        )
                        updated_profile = await profile_service.get_profile_by_user_id(user_uuid)

                print(f"[PROFILE_ANALYSIS] Initial questionnaire saved successfully")

                # Generer la roadmap initiale en meme temps que le profil
                roadmap = None
                try:
                    from src.profile.roadmap_services import RoadmapService

                    roadmap_service = RoadmapService()
                    try:
                        roadmap = await roadmap_service.create_and_save_roadmap(
                            user_id=user_uuid,
                            profil=updated_profile,
                            duration_weeks=12,
                            force_regenerate=True
                        )
                        print(f"[PROFILE_ANALYSIS] Roadmap generated successfully")
                    finally:
                        if hasattr(roadmap_service, "_client"):
                            try:
                                roadmap_service._client.close()
                            except Exception:
                                pass
                except Exception as roadmap_err:
                    print(f"[PROFILE_ANALYSIS] Roadmap generation failed: {roadmap_err}")

                return updated_profile, roadmap

            # Ex√©cuter la fonction async de mani√®re synchrone
            updated_profile, roadmap = async_to_sync(_initial_questionnaire)()

            print(f"[PROFILE_ANALYSIS] Profile level: {updated_profile.niveau if updated_profile else 'N/A'}")

            return {
                "ok": True,
                "is_initial": True,
                "profile_id": str(updated_profile.id) if updated_profile else None,
                "profile_level": updated_profile.niveau if updated_profile else None,
                "roadmap_generated": roadmap is not None,
                "roadmap": roadmap if roadmap else None,
            }

        else:
            # QUIZ NORMAL - √Ä impl√©menter
            print(f"[PROFILE_ANALYSIS] Processing normal quiz...")
            return {"ok": True, "is_initial": False}

    except Exception as e:
        print(f"[PROFILE_ANALYSIS] Task failed with error: {str(e)}")
        import traceback
        traceback.print_exc()
        return {"ok": False, "error": str(e)}


# ... (autres t√¢ches Celery)
@app.task(name="chatbot_streaming_task", bind=True)
def chatbot_streaming_task(self, user_id: str, session_id: str, message: str):
    """
    T√¢che Celery qui stream la r√©ponse GPT-4 via Redis Pub/Sub.

    Cette approche permet:
    - R√©ponse FastAPI imm√©diate (non bloqu√©e)
    - Streaming temps r√©el via WebSocket
    - Scalabilit√© √† 10,000+ utilisateurs simultan√©s

    Args:
        user_id: ID de l'utilisateur
        session_id: ID de session
        message: Message de l'utilisateur

    Returns:
        Dict avec la r√©ponse compl√®te et les m√©tadonn√©es
    """
    from openai import OpenAI
    from src.db.redis import r_sync as redis_client
    from src.profile.services import profile_service
    from src.profile.learning_services import chatbot_service
    from src.ai_agents.agents.chatbot_agent import CHATBOT_SYSTEM_PROMPT
    from datetime import datetime, UTC

    task_id = self.request.id
    channel = f"chatbot_stream:{task_id}"

    try:
        print(f"[CHATBOT_STREAMING] Task {task_id} started for user {user_id}")

        # 1. R√©cup√©rer le profil utilisateur
        profil = async_to_sync(profile_service.get_profile_by_user_id)(user_id)

        user_context = {}
        if profil:
            user_context = {
                "niveau_technique": profil.niveau,
                "competences": profil.competences,
                "objectifs": profil.objectifs,
                "xp": profil.xp,
                "badges": profil.badges
            }

        # 2. Construire le contexte pour le prompt
        context_str = f"""
PROFIL APPRENANT :
- Niveau : {user_context.get('niveau_technique', 5)}/10
- Comp√©tences : {', '.join(user_context.get('competences', [])) or 'Non identifi√©es'}
- Objectifs : {user_context.get('objectifs', 'Non d√©finis')}
- XP : {user_context.get('xp', 0)}
"""

        # 3. Construire les messages pour OpenAI
        messages = [
            {"role": "system", "content": CHATBOT_SYSTEM_PROMPT},
            {"role": "system", "content": f"CONTEXTE UTILISATEUR:\n{context_str}"},
            {"role": "user", "content": message}
        ]

        # 4. Stream depuis OpenAI
        client = OpenAI(api_key=Config.OPENAI_API_KEY)

        stream = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            stream=True,
            temperature=0.7
        )

        full_response = ""
        chunk_count = 0

        # Publier le d√©but du streaming
        redis_client.publish(
            channel,
            json.dumps({
                "type": "stream_started",
                "task_id": task_id,
                "timestamp": datetime.now(UTC).isoformat()
            })
        )

        # 5. Stream les chunks
        for chunk in stream:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                full_response += content
                chunk_count += 1

                # Publier le chunk sur Redis
                redis_client.publish(
                    channel,
                    json.dumps({
                        "type": "chunk",
                        "content": content,
                        "chunk_number": chunk_count,
                        "timestamp": datetime.now(UTC).isoformat()
                    })
                )

        print(f"[CHATBOT_STREAMING] Streamed {chunk_count} chunks, total length: {len(full_response)}")

        # 6. Analyser l'intention
        message_lower = message.lower()
        intentions = {
            "concept_question": any(word in message_lower for word in ["qu'est-ce", "comment", "pourquoi", "expliquer", "d√©finir"]),
            "code_help": any(word in message_lower for word in ["code", "erreur", "bug", "impl√©menter"]),
            "resource_request": any(word in message_lower for word in ["ressource", "cours", "tutoriel", "livre", "vid√©o"]),
            "motivation": any(word in message_lower for word in ["difficile", "bloqu√©", "abandonner", "d√©motiv√©"]),
        }

        primary_intention = max(intentions.items(), key=lambda x: x[1])

        intention = {
            "primary": primary_intention[0],
            "confidence": 0.8 if primary_intention[1] else 0.3,
            "all_intentions": {k: v for k, v in intentions.items() if v}
        }

        # 7. G√©n√©rer des suggestions
        suggestions_map = {
            "concept_question": [
                "üí° Peux-tu me donner un exemple concret ?",
                "üìä Montre-moi un cas d'utilisation",
                "üîó Quel est le lien avec ce que j'ai d√©j√† appris ?"
            ],
            "code_help": [
                "üîç O√π se trouve exactement l'erreur ?",
                "üíª Montre-moi comment d√©boguer",
                "üìù Quelles sont les bonnes pratiques ?"
            ],
            "resource_request": [
                "üìö Quelles ressources pour mon niveau ?",
                "üé• Y a-t-il des vid√©os recommand√©es ?",
                "üíº Des projets pratiques √† faire ?"
            ],
            "motivation": [
                "üéØ Quels sont mes progr√®s jusqu'ici ?",
                "‚ö° Comment rester motiv√© ?",
                "üèÜ Quels sont mes prochains objectifs ?"
            ]
        }

        suggestions = suggestions_map.get(intention["primary"], [
            "üí¨ Pose-moi une question",
            "üìö Voir mes cours",
            "üìä Voir ma progression"
        ])

        # 8. Publier le message de compl√©tion
        redis_client.publish(
            channel,
            json.dumps({
                "type": "complete",
                "full_response": full_response,
                "intention": intention,
                "suggestions": suggestions,
                "timestamp": datetime.now(UTC).isoformat(),
                "stats": {
                    "chunks": chunk_count,
                    "length": len(full_response),
                    "session_id": session_id
                }
            })
        )

        # 9. Sauvegarder dans MongoDB
        try:
            async_to_sync(chatbot_service.add_message)(
                utilisateur_id=user_id,
                session_id=session_id,
                role="user",
                content=message
            )

            async_to_sync(chatbot_service.add_message)(
                utilisateur_id=user_id,
                session_id=session_id,
                role="assistant",
                content=full_response,
                intention=intention
            )
        except Exception as db_error:
            print(f"[CHATBOT_STREAMING] Warning: Failed to save to MongoDB: {db_error}")

        print(f"[CHATBOT_STREAMING] Task {task_id} completed successfully")

        return {
            "status": "success",
            "response": full_response,
            "intention": intention,
            "suggestions": suggestions,
            "chunks_sent": chunk_count,
            "task_id": task_id
        }

    except Exception as e:
        error_msg = str(e)
        print(f"[CHATBOT_STREAMING] Task {task_id} failed: {error_msg}")
        import traceback
        traceback.print_exc()

        # Publier l'erreur sur Redis
        try:
            redis_client.publish(
                channel,
                json.dumps({
                    "type": "error",
                    "error": error_msg,
                    "timestamp": datetime.now(UTC).isoformat()
                })
            )
        except:
            pass

        return {
            "status": "error",
            "error": error_msg,
            "task_id": task_id
        }


# ==================== COURSE GENERATION (ASYNC) ====================

@app.task(name="generate_course_roadmap_task")
def generate_course_roadmap_task(user_id: str, course_topic: str, user_level: int, user_objectives: str, duration_weeks: int):
    """
    T√¢che Celery pour g√©n√©rer une roadmap de cours personnalis√©e.

    Cette approche permet:
    - R√©ponse FastAPI imm√©diate (non bloqu√©e)
    - G√©n√©ration asynchrone de la roadmap en arri√®re-plan
    - √âconomie de ressources serveur

    Args:
        user_id: ID de l'utilisateur
        course_topic: Sujet du cours
        user_level: Niveau de l'utilisateur
        user_objectives: Objectifs d'apprentissage
        duration_weeks: Dur√©e en semaines

    Returns:
        Dict avec la roadmap g√©n√©r√©e et cours cr√©√©
    """
    try:
        import asyncio
        from src.ai_agents.agents.course_manager_agent import course_manager_agent
        from src.profile.learning_services import course_service
        from src.profile.learning_services import progression_service
        from uuid import UUID as _UUID

        user_uuid = _UUID(str(user_id))

        print(f"[COURSE_GENERATION] Starting roadmap generation for user {user_id}")
        print(f"[COURSE_GENERATION] Topic: {course_topic}, Level: {user_level}, Weeks: {duration_weeks}")

        # Cr√©er une nouvelle boucle d'√©v√©nements pour cette op√©ration async
        async def _generate_roadmap():
            # G√©n√©rer la roadmap avec l'agent IA
            print(f"[COURSE_GENERATION] Calling course_manager_agent...")
            roadmap = await course_manager_agent.create_course_roadmap(
                course_topic=course_topic,
                user_level=user_level,
                user_objectives=user_objectives,
                duration_weeks=duration_weeks
            )
            print(f"[COURSE_GENERATION] Roadmap generated: {roadmap.get('titre')}")

            # Sauvegarder le cours dans MongoDB
            print(f"[COURSE_GENERATION] Saving course to MongoDB...")
            course_id = await course_service.create_course(roadmap)
            print(f"[COURSE_GENERATION] Course created with ID: {course_id}")

            # Cr√©er la progression pour l'utilisateur
            print(f"[COURSE_GENERATION] Creating progression...")
            await progression_service.create_progression(
                utilisateur_id=user_uuid,
                course_id=roadmap["cours"]["id"]
            )

            # Incr√©menter les inscriptions
            print(f"[COURSE_GENERATION] Incrementing enrollment...")
            await course_service.increment_enrollment(roadmap["cours"]["id"])

            return {
                "course_id": course_id,
                "roadmap": roadmap
            }

        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            result = loop.run_until_complete(_generate_roadmap())
        finally:
            loop.close()

        print(f"[COURSE_GENERATION] Roadmap generation completed successfully")

        return {
            "ok": True,
            "course_id": result["course_id"],
            "roadmap": result["roadmap"]
        }

    except Exception as e:
        print(f"[COURSE_GENERATION] Task failed with error: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            "ok": False,
            "error": str(e)
        }
