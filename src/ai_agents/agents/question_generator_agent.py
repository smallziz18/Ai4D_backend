"""
Agent gÃ©nÃ©rateur de questions - GÃ©nÃ¨re des questions adaptÃ©es au profil.
"""
from typing import Dict, Any, List
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
import json

from src.config import Config
from src.ai_agents.agent_state import AgentState
from src.ai_agents.shared_context import shared_context_service


QUESTION_GENERATOR_SYSTEM_PROMPT = """
Tu es un gÃ©nÃ©rateur expert de questions sur l'INTELLIGENCE ARTIFICIELLE uniquement.

ðŸŽ¯ Ta mission :
GÃ©nÃ©rer des questions adaptÃ©es au niveau et objectifs de l'apprenant.
INTERDICTION FORMELLE de gÃ©nÃ©rer des questions sur :
âŒ Python gÃ©nÃ©ral, SQL, bases de donnÃ©es, R, Pandas, NumPy (sauf contexte IA explicite)

âœ… SUJETS AUTORISÃ‰S (Intelligence Artificielle uniquement) :
- Machine Learning : algorithmes, modÃ¨les, apprentissage supervisÃ©/non supervisÃ©
- Deep Learning : rÃ©seaux de neurones, CNN, RNN, LSTM, Transformers, Attention
- NLP : traitement du langage naturel, embeddings, BERT, GPT
- Computer Vision : reconnaissance d'images, dÃ©tection d'objets, segmentation
- Reinforcement Learning : Q-learning, policy gradients, AlphaGo
- Outils IA : TensorFlow, PyTorch, Keras, scikit-learn, Hugging Face
- Concepts IA : overfitting, underfitting, backpropagation, gradient descent, loss functions

ðŸ“‹ TYPES DE QUESTIONS Ã  gÃ©nÃ©rer :
1. **ChoixMultiple** : 4 options (A/B/C/D), une seule correcte
2. **VraiOuFaux** : TOUJOURS "A. Vrai" et "B. Faux" (format obligatoire)
3. **QuestionOuverte** : âš ï¸ CRUCIAL - RÃ©vÃ¨le la vraie comprÃ©hension conceptuelle
4. **ListeOuverte** : Demande plusieurs Ã©lÃ©ments (ex: "Citez 3 types de rÃ©seaux de neurones")

âš ï¸ RÃˆGLES STRICTES POUR VRAI/FAUX :
- TOUJOURS utiliser les options : ["A. Vrai", "B. Faux"]
- La correction doit commencer par "A - " ou "B - "
- Varier les rÃ©ponses : Ã©viter que toutes les VraiOuFaux aient la mÃªme rÃ©ponse (mÃ©langer A et B)
- **AFFIRMATION COMPLÃˆTE OBLIGATOIRE** : Une question VraiOuFaux doit Ãªtre une phrase complÃ¨te avec un verbe conjuguÃ©
  âœ… BON: "Le sur-apprentissage se produit lorsque le modÃ¨le mÃ©morise les donnÃ©es d'entraÃ®nement."
  âŒ MAUVAIS: "Le sur-apprentissage se produit lorsque :"
  âœ… BON: "Les CNN sont principalement utilisÃ©s pour le traitement d'images."
  âŒ MAUVAIS: "Les CNN sont utilisÃ©s pour ?"
  
- Exemple VraiOuFaux correct :
  {
    "question": "La backpropagation utilise la dÃ©rivation en chaÃ®ne.",
    "type": "VraiOuFaux",
    "options": ["A. Vrai", "B. Faux"],
    "correction": "A - La backpropagation repose sur la rÃ¨gle de dÃ©rivation en chaÃ®ne."
  }

âš ï¸ IMPORTANCE DES QUESTIONS OUVERTES :
- Elles sont LA SOURCE DE VÃ‰RITÃ‰ pour Ã©valuer le niveau rÃ©el
- Minimum 30% de questions ouvertes (QuestionOuverte + ListeOuverte)
- Elles doivent tester la comprÃ©hension conceptuelle profonde
- Exemples : "Explique comment fonctionne la backpropagation", "Pourquoi utilise-t-on la normalisation batch ?"

ðŸ“Š ADAPTATION AU NIVEAU :
- Niveau 1-3 (DÃ©butant) : Concepts de base, dÃ©finitions simples
- Niveau 4-6 (IntermÃ©diaire) : Applications pratiques, comparaisons
- Niveau 7-10 (Expert) : Architectures avancÃ©es, optimisations, cas edge

FORMAT JSON STRICT (pas de texte avant/aprÃ¨s) :
[
  {
    "numero": 1,
    "question": "Quelle est la diffÃ©rence entre apprentissage supervisÃ© et non supervisÃ© ?",
    "type": "ChoixMultiple",
    "options": ["A. L'un utilise des labels", "B. L'un est plus rapide", "C. Pas de diffÃ©rence", "D. L'un utilise moins de donnÃ©es"],
    "correction": "A - L'apprentissage supervisÃ© utilise des donnÃ©es Ã©tiquetÃ©es pour entraÃ®ner le modÃ¨le."
  },
  {
    "numero": 2,
    "question": "Le sur-apprentissage se produit lorsque le modÃ¨le mÃ©morise les donnÃ©es d'entraÃ®nement.",
    "type": "VraiOuFaux",
    "options": ["A. Vrai", "B. Faux"],
    "correction": "A - Le sur-apprentissage (overfitting) se produit quand le modÃ¨le s'adapte trop aux donnÃ©es d'entraÃ®nement et perd en gÃ©nÃ©ralisation."
  },
  {
    "numero": 3,
    "question": "Les CNN sont principalement utilisÃ©s pour le traitement du langage naturel.",
    "type": "VraiOuFaux",
    "options": ["A. Vrai", "B. Faux"],
    "correction": "B - Les CNN (Convolutional Neural Networks) sont principalement utilisÃ©s pour la vision par ordinateur, pas le NLP."
  },
  {
    "numero": 4,
    "question": "Explique en dÃ©tail comment fonctionne l'algorithme de backpropagation.",
    "type": "QuestionOuverte",
    "options": [],
    "correction": "La backpropagation calcule le gradient de la loss function par rapport aux poids du rÃ©seau en propageant l'erreur de la sortie vers l'entrÃ©e, utilisant la rÃ¨gle de dÃ©rivation en chaÃ®ne."
  }
]
"""


class QuestionGeneratorAgent:
    """
    Agent de gÃ©nÃ©ration de questions adaptatives.
    GÃ©nÃ¨re des questions basÃ©es sur le profil et la stratÃ©gie d'apprentissage.
    """

    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            api_key=Config.OPENAI_API_KEY,
            temperature=0.7  # CrÃ©ativitÃ© modÃ©rÃ©e pour variÃ©tÃ©
        )
        self.name = "QuestionGeneratorAgent"

    async def generate_questions(
        self,
        state: AgentState,
        num_questions: int = 10
    ) -> Dict[str, Any]:
        """
        GÃ©nÃ©rer des questions adaptÃ©es au profil utilisateur.

        Args:
            state: Ã‰tat actuel du workflow
            num_questions: Nombre de questions Ã  gÃ©nÃ©rer

        Returns:
            Mises Ã  jour Ã  appliquer Ã  l'Ã©tat
        """
        user_profile = state.get("user_profile", {})
        user_level = state.get("user_level", 5)
        profiler_analysis = state.get("meta_data", {}).get("profiler_analysis", {})
        user_id = state.get("user_id")
        session_id = state.get("session_id")

        # RÃ©cupÃ©rer la stratÃ©gie de profilage
        priority_domains = profiler_analysis.get("priority_domains", ["machine_learning"])
        learning_style = profiler_analysis.get("learning_style", "balanced")

        # Construire le contexte
        context = {
            "niveau": user_level,
            "domaines_prioritaires": priority_domains,
            "style_apprentissage": learning_style,
            "competences_actuelles": state.get("user_competences", []),
            "objectifs": state.get("user_objectifs", "")
        }

        context_json = json.dumps(context, indent=2, ensure_ascii=False)

        messages = [
            SystemMessage(content=QUESTION_GENERATOR_SYSTEM_PROMPT),
            HumanMessage(content=f"""
GÃ©nÃ¨re {num_questions} questions d'Ã©valuation IA adaptÃ©es Ã  ce profil :

CONTEXTE UTILISATEUR :
{context_json}

CONTRAINTES :
- {num_questions} questions au total
- Au moins 30% de questions ouvertes (QuestionOuverte + ListeOuverte)
- Adapter la difficultÃ© au niveau {user_level}/10
- Prioriser les domaines : {', '.join(priority_domains)}
- Style d'apprentissage : {learning_style}

TYPES Ã  inclure (exemple pour 10 questions) :
- 4 ChoixMultiple
- 2 VraiOuFaux âš ï¸ IMPORTANT: Varier les rÃ©ponses (1 Vrai + 1 Faux) pour Ã©viter biais
- 3 QuestionOuverte âš ï¸ CRUCIAL
- 1 ListeOuverte âš ï¸ CRUCIAL

âš ï¸ ANTI-BIAIS VRAI/FAUX :
Pour Ã©viter les biais, alterner les rÃ©ponses correctes :
- Si 2 questions VraiOuFaux : 1 rÃ©ponse A (Vrai) + 1 rÃ©ponse B (Faux)
- Si 3 questions VraiOuFaux : 2 A + 1 B ou 1 A + 2 B
- JAMAIS toutes les VraiOuFaux avec la mÃªme rÃ©ponse

GÃ©nÃ¨re maintenant les questions en JSON uniquement (pas de texte avant/aprÃ¨s).
            """)
        ]

        try:
            response = await self.llm.ainvoke(messages)
            response_text = response.content

            # Nettoyer et parser JSON
            if "```json" in response_text:
                response_text = response_text.split("```json")[1].split("```")[0].strip()
            elif "```" in response_text:
                response_text = response_text.split("```")[1].split("```")[0].strip()

            questions = json.loads(response_text)

            # Validation basique
            if not isinstance(questions, list) or len(questions) == 0:
                raise ValueError("Format de questions invalide")

            # âš ï¸ NORMALISATION ET VALIDATION DES QUESTIONS VRAI/FAUX
            # Garantir que toutes les questions VraiOuFaux ont exactement les options A. Vrai / B. Faux
            invalid_vf_indices = []
            for idx, q in enumerate(questions):
                if q.get("type") == "VraiOuFaux":
                    question_text = q.get("question", "")

                    # ðŸš¨ VALIDATION: DÃ©tecter questions invalides/incomplÃ¨tes
                    # Une question VraiOuFaux doit Ãªtre une AFFIRMATION COMPLÃˆTE
                    invalid_patterns = [
                        question_text.endswith(":"),  # "Le surapprentissage se produit lorsque :"
                        question_text.endswith("..."),  # Question incomplÃ¨te
                        " est :" in question_text.lower() and question_text.endswith(":"),
                        " sont :" in question_text.lower() and question_text.endswith(":"),
                        question_text.count("?") > 0,  # Questions interrogatives ne conviennent pas
                        len(question_text.split()) < 5,  # Question trop courte
                    ]

                    if any(invalid_patterns):
                        # Marquer pour conversion en ChoixMultiple
                        invalid_vf_indices.append(idx)
                        continue

                    # Forcer les options standards
                    q["options"] = ["A. Vrai", "B. Faux"]

                    # VÃ©rifier que la correction commence par A ou B
                    correction = q.get("correction", "")
                    if not correction.startswith("A") and not correction.startswith("B"):
                        # Si pas de A/B au dÃ©but, analyser le sens de la correction
                        correction_lower = correction.lower()
                        if any(word in correction_lower for word in ["vrai", "correct", "exact", "oui"]):
                            q["correction"] = "A - " + correction
                        else:
                            q["correction"] = "B - " + correction

            # Convertir les VraiOuFaux invalides en ChoixMultiple
            for idx in invalid_vf_indices:
                q = questions[idx]
                # Transformer en QCM avec 4 options pertinentes
                q["type"] = "ChoixMultiple"
                # Les options seront gÃ©nÃ©riques mais cohÃ©rentes
                q["options"] = [
                    "A. Toujours dans tous les cas",
                    "B. Jamais",
                    "C. Selon le contexte",
                    "D. Uniquement avec certaines conditions"
                ]
                # Garder la correction existante ou mettre une valeur par dÃ©faut
                if not q.get("correction", "").startswith(("A", "B", "C", "D")):
                    q["correction"] = "C - Cela dÃ©pend du contexte spÃ©cifique."

            # âš ï¸ ANTI-BIAIS: Forcer diversitÃ© des rÃ©ponses VraiOuFaux
            vf_questions = [q for q in questions if q.get("type") == "VraiOuFaux"]
            if len(vf_questions) >= 2:
                a_count = sum(1 for q in vf_questions if q.get("correction", "").startswith("A"))
                b_count = len(vf_questions) - a_count

                # Si toutes les rÃ©ponses sont identiques, inverser une question
                if a_count == 0 or b_count == 0:
                    # Inverser la derniÃ¨re question pour crÃ©er de la diversitÃ©
                    last_vf = vf_questions[-1]
                    current_answer = last_vf["correction"][0]  # A ou B

                    if current_answer == "A":
                        # Reformuler la question pour que la rÃ©ponse soit B (Faux)
                        question_text = last_vf["question"]
                        # Ajouter une nÃ©gation si pas dÃ©jÃ  prÃ©sente
                        if " ne " not in question_text.lower() and " pas " not in question_text.lower():
                            # Trouver le verbe et ajouter "ne...pas"
                            words = question_text.split()
                            if len(words) > 2:
                                # Heuristique simple: ajouter "ne" aprÃ¨s le premier mot (souvent le sujet)
                                negated = f"{words[0]} ne {' '.join(words[1:])}"
                                if negated[-1] == "?":
                                    negated = negated[:-1] + " pas?"
                                else:
                                    negated += " pas"
                                last_vf["question"] = negated
                        last_vf["correction"] = "B - " + last_vf["correction"].split(" - ", 1)[1]
                    else:
                        # Retirer la nÃ©gation pour que la rÃ©ponse soit A (Vrai)
                        question_text = last_vf["question"]
                        question_text = question_text.replace(" ne ", " ").replace(" pas", "")
                        last_vf["question"] = question_text
                        last_vf["correction"] = "A - " + last_vf["correction"].split(" - ", 1)[1]

            # Compter les questions ouvertes
            open_questions = [q for q in questions if q.get("type") in ["QuestionOuverte", "ListeOuverte"]]
            open_percentage = len(open_questions) / len(questions) * 100

            await shared_context_service.add_message(
                user_id,
                session_id,
                self.name,
                f"GÃ©nÃ©rÃ© {len(questions)} questions (dont {len(open_questions)} ouvertes - {open_percentage:.0f}%)"
            )

            # Enregistrer la dÃ©cision
            decision = {
                "agent": self.name,
                "timestamp": state.get("updated_at"),
                "decision": "questions_generated",
                "details": {
                    "num_questions": len(questions),
                    "num_open_questions": len(open_questions),
                    "open_percentage": open_percentage
                }
            }

            return {
                "questions": questions,
                "agent_decisions": state.get("agent_decisions", []) + [decision],
                "current_step": "questions_generated",
                "next_step": "awaiting_responses"
            }

        except Exception as e:
            error_msg = f"Erreur dans QuestionGeneratorAgent: {str(e)}"

            await shared_context_service.add_message(
                user_id,
                session_id,
                self.name,
                error_msg,
                message_type="system"
            )

            return {
                "error_message": error_msg,
                "needs_human_review": True
            }

    def __call__(self, state: AgentState) -> Dict[str, Any]:
        """Permet d'utiliser l'agent comme une fonction"""
        import asyncio
        return asyncio.run(self.generate_questions(state))


# Instance globale
question_generator_agent = QuestionGeneratorAgent()

